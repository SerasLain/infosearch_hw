{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "sem4_ML_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SerasLain/infosearch_hw/blob/master/sem4_ML_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdH73FvIeYj5",
        "colab_type": "text"
      },
      "source": [
        "# Лабораторная работа\n",
        "## Ранжирование с помощью ML\n",
        "\n",
        "\n",
        "![](https://avatars.mds.yandex.net/get-research/1677227/2a00000168a82fc9b0eac19e430b8454a656/orig)\n",
        "\n",
        "\n",
        "Одна из отличительных особенностей задачи ранжирования от классических задач машинного обучения заключается в том, что качество результата зависит не от предсказанных оценок релевантности, а от порядка следования документов в рамках конкретного запроса, т.е. важно не абсолютное значение релевантности (его достаточно трудно формализовать в виде числа), а то, более или менее релевантен документ, относительно других документов.\n",
        "\n",
        "### Подходы к решению задачи ранжирования\n",
        "Существуют 3 основных подхода к ранжированию, различие между которыми заключается в том, на какую функцию потерь они опираются:\n",
        "  \n",
        "1. **Поточечный подход (pointwise)**. В этом подходе предполагается, что каждой паре запрос-документ поставлена в соответствие численная оценка. Задача обучения ранжированию сводится к построению регрессии: для каждой отдельной пары запрос-документ необходимо предсказать её оценку.\n",
        "\n",
        "2. **Попарный подход (pairwise)**. В таком подходе обучение ранжированию сводится к построению бинарного классификатора, которому на вход поступают два документа, соответствующих одному и тому же запросу, и требуется определить, какой из них лучше. Другими словами, функция потерь штрафует модель, если отранжированная этой моделью пара документов оказалась в неправильном порядке.\n",
        "\n",
        "3. **Списочный подход (listwise)**. Его суть заключается в построении модели, на вход которой поступают сразу все документы, соответствующие запросу, а на выходе получается их перестановка.\n",
        "\n",
        "\n",
        "Будем использовать самый простой подход - поточечный."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5q3Sl8OZeYj8",
        "colab_type": "text"
      },
      "source": [
        "### Оценка качества\n",
        "\n",
        "Для оценивания качества ранжирования найденных документов в поиске традиционно используется метрика *DCG* ([Discounted Cumulative Gain](https://en.wikipedia.org/wiki/Discounted_cumulative_gain)) и ее нормализованный вариант — *nDCG*, всегда принимающий значения от 0 до 1.\n",
        "\n",
        "Для одного запроса DCG считается следующим образом:\n",
        "$$ DCG(Q) = \\sum_{i=1}^{numpos}\\frac{(2^{rel_i} - 1)}{\\log_2(i+1)}, $$\n",
        "где\n",
        ">$numpos$ — количество документов в поисковой выдаче, среди которых мы оценимваем качество (например, в предудыщих заданиях *num_pos* был равен 5)  \n",
        "$rel_i$ — оценка релевантности документа, находящегося на i-той позиции   \n",
        "   \n",
        "\n",
        "Нормализованный вариант *nDCG* получается делением *DCG* на максимальное из его значений:\n",
        "\n",
        "$$nDCG = \\frac{DCG}{IDCG} \\in [0, 1].$$\n",
        "> *IDCG* — наибольшее из возможных значение *DCG* \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Чтобы оценить значение *nDCG* на выборке $Queries$ ($nDCG_{Queries}$) размера $N$, необходимо усреднить значение *nDCG* по всем запросам  выборки:\n",
        "$$nDCG_{Queries} = \\frac{1}{N}\\sum_{q \\in Queries}nDCG(q).$$\n",
        "\n",
        "Пример реализации метрик ранжирование на python можно найти [здесь](https://gist.github.com/mblondel/7337391)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJexuQhZeYkB",
        "colab_type": "text"
      },
      "source": [
        "# Погнали\n",
        "###  **Задача: предсказать оценку релевантности для запросов тестового датасета**\n",
        "\n",
        "\n",
        "Мы будем работать на данных с конкурса [Интернет-математика 2009](https://academy.yandex.ru/events/data_analysis/grant2009/). По ссылке можно прочитать описание данных.      \n",
        "\n",
        "Данные\n",
        "> Данные разбиты на две выборки – обучающая выборка imat2009_learning.txt с известными оценками близости запроса и документа и тестовая выборка с неизвестными близостями imat2009_test.txt  \n",
        "\n",
        "Обучающая выборка\n",
        "> Данные для обучения содержат **97 290 строк**, которые соответствуют **9 124 запросам**  \n",
        "Каждая строка соответствует паре «запрос-документ»    \n",
        "\n",
        "Признаки\n",
        ">Каждой паре «запрос-документ» соответствуют значения **245 признаков**. Формат хранения feat_num:value. Если значение признака равно 0, то он опускается.     \n",
        "В комментариях в конце каждой строки указан **идентификатор запроса**.   \n",
        "Файл с обучающей выборкой содержит **оценку релевантности**, значения из диапазона **[0, 4]** (4 – «высокая релевантность», 0 – «нерелевантно»).   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRdxWRJdtUkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "b0717526-0730-4d93-986d-12bc7a124ae7"
      },
      "source": [
        "!wget \"https://sun9-46.userapi.com/c851520/v851520155/763ba/iKNBViWyZAs.jpg\""
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-17 21:57:19--  https://sun9-46.userapi.com/c851520/v851520155/763ba/iKNBViWyZAs.jpg\n",
            "Resolving sun9-46.userapi.com (sun9-46.userapi.com)... 87.240.185.149\n",
            "Connecting to sun9-46.userapi.com (sun9-46.userapi.com)|87.240.185.149|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 210163 (205K) [image/jpeg]\n",
            "Saving to: ‘iKNBViWyZAs.jpg’\n",
            "\n",
            "iKNBViWyZAs.jpg     100%[===================>] 205.24K  --.-KB/s    in 0.07s   \n",
            "\n",
            "2019-10-17 21:57:21 (2.81 MB/s) - ‘iKNBViWyZAs.jpg’ saved [210163/210163]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVqC9fSfuFW-",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"/content/iKNBViWyZAs.jpg\" style=\"height:300px\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCCeesgzeYkE",
        "colab_type": "text"
      },
      "source": [
        "### DATA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc8p3AEBfFng",
        "colab_type": "code",
        "outputId": "f52ae964-16ec-46eb-ea0e-c45dfc1604ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "!wget \"https://github.com/hse-infosearch/infosearch/blob/master/4%20ML%20ranking/imat2009_learning.txt.zip?raw=true\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-17 20:02:24--  https://github.com/hse-infosearch/infosearch/blob/master/4%20ML%20ranking/imat2009_learning.txt.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/hse-infosearch/infosearch/raw/master/4%20ML%20ranking/imat2009_learning.txt.zip [following]\n",
            "--2019-10-17 20:02:25--  https://github.com/hse-infosearch/infosearch/raw/master/4%20ML%20ranking/imat2009_learning.txt.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/hse-infosearch/infosearch/master/4%20ML%20ranking/imat2009_learning.txt.zip [following]\n",
            "--2019-10-17 20:02:25--  https://raw.githubusercontent.com/hse-infosearch/infosearch/master/4%20ML%20ranking/imat2009_learning.txt.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 30848550 (29M) [application/zip]\n",
            "Saving to: ‘imat2009_learning.txt.zip?raw=true’\n",
            "\n",
            "imat2009_learning.t 100%[===================>]  29.42M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-10-17 20:02:26 (208 MB/s) - ‘imat2009_learning.txt.zip?raw=true’ saved [30848550/30848550]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TqtnQ5af3iy",
        "colab_type": "code",
        "outputId": "f4f3dbae-fa17-48b8-f94d-90f72022ad2b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!unzip \"imat2009_learning.txt.zip?raw=true\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  imat2009_learning.txt.zip?raw=true\n",
            "  inflating: imat2009_learning.txt   \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._imat2009_learning.txt  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBP7PWZLj7uW",
        "colab_type": "code",
        "outputId": "cf53322e-b9ef-4f2a-c553-8365487abf61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/hse-infosearch/infosearch/master/4%20ML%20ranking/metrics.py\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-10-17 20:02:34--  https://raw.githubusercontent.com/hse-infosearch/infosearch/master/4%20ML%20ranking/metrics.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4914 (4.8K) [text/plain]\n",
            "Saving to: ‘metrics.py’\n",
            "\n",
            "\rmetrics.py            0%[                    ]       0  --.-KB/s               \rmetrics.py          100%[===================>]   4.80K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-10-17 20:02:34 (92.5 MB/s) - ‘metrics.py’ saved [4914/4914]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8ggaf0NeYkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# LOAD TRAIN DATA\n",
        "file_learning = 'imat2009_learning.txt'\n",
        "\n",
        "with open(file_learning) as f:\n",
        "    train_data = f.readlines()\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zcWZwUfeYkT",
        "colab_type": "code",
        "outputId": "4e055f6b-40b3-4f57-9413-7543d8b5f442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(train_data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97290"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPWkXFVgeYkg",
        "colab_type": "text"
      },
      "source": [
        "Структура данных следующая - первый элемент в строке - это оценка близости запроса и документа, дальше идут признаки документа, а последний элемент строки - это id запроса:\n",
        "\n",
        "> RELEVANCE      feature:value feature:value ... feature:value     # QUERY_ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us34kgVneYkm",
        "colab_type": "code",
        "outputId": "d7d03c73-178b-4bed-9e3c-5312c895f4d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1 1:0.000023 7:0.704953 8:0.550315 9:0.032294 11:0.712631 14:0.015686 15:0.137255 16:0.302576 17:1.000000 18:0.996078 22:1.000000 23:1.000000 24:1.000000 27:0.700000 28:0.587629 29:0.999881 30:0.032294 34:0.000023 36:0.431373 37:0.002247 38:0.054902 41:1.000000 46:0.002247 50:0.032294 51:0.325613 52:0.056641 53:0.820677 54:0.388235 55:0.450980 56:0.312547 57:0.004672 59:1.000000 61:0.000023 65:1.000000 68:0.712195 69:0.001400 70:1.000000 71:0.001013 73:0.709459 74:0.560784 76:0.142857 77:0.360800 78:1.000000 79:1.000000 80:1.000000 82:0.000023 83:1.000000 85:0.996078 86:0.070588 87:1.000000 88:0.999797 92:1.000000 93:0.714286 95:0.039216 97:0.000023 98:0.356490 99:0.165041 102:1.000000 103:1.000000 104:1.000000 105:0.486275 108:0.152941 120:0.996078 121:0.676507 122:0.032294 126:0.712980 128:0.121569 129:0.609261 132:1.000000 134:0.109804 135:0.030535 140:0.002247 142:0.698039 144:0.248111 145:0.356490 146:1.000000 147:0.498039 148:0.125490 150:0.704953 151:1.000000 152:0.098039 154:0.676507 156:0.066667 157:0.001470 160:0.101961 162:0.302576 165:0.843126 166:0.400000 167:0.019608 168:0.056641 171:1.000000 172:0.857143 177:0.285714 178:0.588235 179:0.820677 180:0.032294 181:0.196491 182:0.729730 185:0.756863 192:1.000000 193:1.000000 197:0.032294 202:0.310127 203:0.001186 205:1.000000 206:0.999835 209:0.291145 210:0.980392 211:0.960784 212:0.032294 213:0.000023 214:1.000000 216:0.999998 217:0.146074 219:0.300000 222:0.666667 224:0.145098 227:0.007089 228:1.000000 229:1.000000 230:0.032294 232:1.000000 233:0.494217 236:0.032749 243:0.000023 244:1.000000 245:0.000023 # 3382\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly0UHcwNeYkx",
        "colab_type": "text"
      },
      "source": [
        "В test_data все оценки релевантности скрыты, поскольку этот набор данных использовался для проверки качества работы алгоритма в конкурсе. Нам эти данные не нужны, дальше работаем только с **train_data**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIcU0wAjeYkz",
        "colab_type": "text"
      },
      "source": [
        "Для проверки качества будущей модели надо разбить обучающую выборку на обучение и валидацию в соотношении 70 / 30\n",
        "\n",
        "Внимание: разбивать необходимо **множество запросов QUERY_ID**, а не строчки датасета, чтобы в выборке находилась вся информация по запросу\n",
        "\n",
        "Для этого вам надо:\n",
        "1. собрать все запросы для каждого QUERY_ID\n",
        "\n",
        "```\n",
        "{\n",
        "query_id : [\n",
        "    RELEVANCE feature:value ... feature:value,\n",
        "    ...\n",
        "],\n",
        "...\n",
        "}\n",
        "```\n",
        "\n",
        "При этом я бы сразу собирала не сами данные, а номер строки в матрице данных\n",
        "```\n",
        "{\n",
        "query_id : [\n",
        "    line_num, line_num, ... line_num\n",
        "],\n",
        "...\n",
        "}\n",
        "```\n",
        "2. собрать матрицу данных, размер вектора равен числу признаков = 245\n",
        "```\n",
        "data = np.zeros((len(train_data), feats_num), dtype=np.float32) \n",
        "```\n",
        "\n",
        "3. собрать вектор с оценками релевантности, его размер равен размеру train_data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hsmtwHKl6u3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "labels = [] \n",
        "queries_lines_info = defaultdict(list) \n",
        "data = np.zeros((len(train_data), 245), dtype=np.float32)\n",
        "\n",
        "for i, line in enumerate(train_data):\n",
        "    info = line.strip('\\n').split(' ')\n",
        "    labels.append(float(info[0]))\n",
        "    values =[f.split(':') for f in info[1:-2]]\n",
        "    query = int(info[-1])\n",
        "\n",
        "    queries_lines_info[query].append(i)\n",
        "    for column, value in values:\n",
        "        data[i, int(column) - 1] = float(value)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg6vjfydlOTK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0055dc6-0d1d-46a4-aaed-f8a8a10f98fd"
      },
      "source": [
        "assert data.shape == (len(train_data), 245)\n",
        "assert len(queries_lines_info.keys()) == 9124\n",
        "assert len(labels) == len(train_data)\n",
        "print('OK!')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R2HOx9A5eYlE",
        "colab_type": "text"
      },
      "source": [
        "Разделим запросы из *queries_lines_info.keys()* на обучающую *train_queries_ids* и валидационную выборки *test_queries_ids* (70/30)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdgjqJq0la9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "queries_id_train, queries_id_test = train_test_split(list(queries_lines_info.keys()), test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpDMZmIlmCML",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check\n",
        "assert len(queries_id_train) / (len(queries_id_train) + len(queries_id_test)) == 0.6999123191582639"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f08kunLFeYlR",
        "colab_type": "text"
      },
      "source": [
        " > Теперь у нас есть:  \n",
        " 1) айдишники запросов для обучения и валидации **queries_id_train, queries_id_test**   \n",
        " 2) матрица данных **data**   \n",
        " 3) словарь **queries** с информацией о том, какие строчки в этой матрице соответствуют какому айдишнику  \n",
        " \n",
        " С помощью этих данных разделите матрицу data на матрицы **X_train, y_train, X_test, y_test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnW8GEhseYlT",
        "colab_type": "code",
        "outputId": "002ef63d-de1b-4609-df17-58367cfa6d87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# изи пизи способ получить несколько строк матрицы по их id данные матрицы\n",
        "data_example = np.array(\n",
        "    [\n",
        "        [0, 0, 0],\n",
        "        [1, 1, 1],\n",
        "        [2, 2, 2],\n",
        "        [3, 3, 3]\n",
        "    ]\n",
        ")\n",
        "\n",
        "data_example[[0, 3]]"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0],\n",
              "       [3, 3, 3]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZzd8x6-o8dK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# разбиваем номера строк исходной матрицы на train и test\n",
        "\n",
        "train_queries_lines_info = []\n",
        "for i in queries_id_train:\n",
        "    train_queries_lines_info += queries_lines_info[i]\n",
        "\n",
        "test_queries_lines_info = []\n",
        "for i in queries_id_test:\n",
        "    test_queries_lines_info += queries_lines_info[i]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0LoilVqeYlZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = np.array(labels)\n",
        "train_queries_lines_info = np.array(train_queries_lines_info)\n",
        "test_queries_lines_info = np.array(test_queries_lines_info)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VSevh7tpf4P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dbcb7382-9914-4be3-9eec-12734c95a5d0"
      },
      "source": [
        "X_train, X_test = data[train_queries_lines_info], data[test_queries_lines_info]\n",
        "y_train, y_test = labels[train_queries_lines_info], labels[test_queries_lines_info] \n",
        "X_train.shape, y_train.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((68418, 245), (68418,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72AKOycoeYlc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "25a0b41d-6a64-4386-a041-3c616f0129fe"
      },
      "source": [
        "assert X_train.shape == (68418, 245) \n",
        "assert len(y_train) == 68418\n",
        "\n",
        "print('OK!')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OK!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2TLLq_QeYlf",
        "colab_type": "text"
      },
      "source": [
        "Поздравляю, если вы все сделали до этого моменты, вы восхитительны! \n",
        "\n",
        "Данные готовы, можно заряжать модели                                                           \n",
        "Для оценивания качества моделей используйте метрику nDCG, реализованную ниже"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fq4LRWtgeYlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import metrics\n",
        "\n",
        "\n",
        "def get_nDCG_score(queries, queries_lines_info, test_queries_lines_info, labels_true, labels_predicted):\n",
        "    nDCG_scores = [] # nDCG по каждому запросу\n",
        "    \n",
        "    for query in queries:\n",
        "        \n",
        "        query_lines = queries_lines_info[query]\n",
        "        query_lines_in_testdata = [np.where(test_queries_lines_info==line)[0][0] for line in query_lines]\n",
        "        \n",
        "        query_labels_true = labels[query_lines]\n",
        "        query_labels_pred = labels_predicted[query_lines_in_testdata]\n",
        "        \n",
        "        nDCG = metrics.ndcg_score(query_labels_true, query_labels_pred, k=10)\n",
        "        nDCG_scores.append(nDCG)\n",
        "        \n",
        "    nDCG_Queries = np.sum(nDCG_scores) / len(queries) # усредняем по всем запросам\n",
        "    return nDCG_Queries\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfJNTBbReYlj",
        "colab_type": "text"
      },
      "source": [
        "### FIT PREDICT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "1-Mpw0NseYlk",
        "colab_type": "text"
      },
      "source": [
        "Воспользовавшись известными вам техниками построения линейной регрессии, обучите модель, предсказывающую оценку асессора\n",
        "\n",
        "``` from sklearn.linear_model import LinearRegression``` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD0FqLY0eYll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "gs_lr = GridSearchCV(lin_reg, {'fit_intercept': [True, False], 'normalize':[True, False]}, cv=5)\n",
        "gs_lr.fit(X_train, y=y_train)\n",
        "\n",
        "\n",
        "lin_reg_y_pred = gs_lr.best_estimator_.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "koM7aUZJeYlo",
        "colab_type": "code",
        "outputId": "9bfbc286-4954-4e34-fd49-c5ab37955ec6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "h = plt.hist(lin_reg_y_pred, bins=20)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpYL8p8swnba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8169452a-9443-4f34-c38f-838e42d69765"
      },
      "source": [
        "lin_reg_y_pred.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28872,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sd1_D8gw_2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test = [float(i) for i in y_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcIOgWI2WdT3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "6d31dc4f-d945-4b91-8838-2c11ad27335b"
      },
      "source": [
        "lin_reg_y_pred"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.6630007, 2.1945872, 1.3478256, ..., 0.9766481, 0.2451429,\n",
              "       0.7840549], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRFbjpYxeYlr",
        "colab_type": "text"
      },
      "source": [
        "Посчитаем качество модели по метрике **nDCG**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1NR7YyYeYls",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fe9c0a87-e037-4e0f-e6d2-0017a0624f05"
      },
      "source": [
        "import numpy\n",
        "\n",
        "score_lin_reg = get_nDCG_score(\n",
        "    queries = queries_id_test, \n",
        "    queries_lines_info = queries_lines_info, \n",
        "    test_queries_lines_info = test_queries_lines_info, \n",
        "    labels_true = y_test, \n",
        "    labels_predicted = lin_reg_y_pred\n",
        ")\n",
        " \n",
        "score_lin_reg"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.828374168857091"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPgfszBMeYlu",
        "colab_type": "text"
      },
      "source": [
        "Давайте теперь решим эту задачу не как регрессию, а как классификацию"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BH31NeATxfs-",
        "colab_type": "text"
      },
      "source": [
        "А давайте нет? Дело в том, что для того, чтобы представить это как задачу классификации, придется искусственно классифицировать лейблы. Сейчас список лейблов выглядит так:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohzx80QTxwRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8a2c50b5-1b09-469d-af2d-2f6ac511e906"
      },
      "source": [
        "print(len(set(labels)))\n",
        "\n",
        "set(labels)"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.0,\n",
              " 0.125,\n",
              " 0.166671,\n",
              " 0.2,\n",
              " 0.222229,\n",
              " 0.25,\n",
              " 0.333329,\n",
              " 0.4,\n",
              " 0.5,\n",
              " 0.583329,\n",
              " 0.6,\n",
              " 0.666671,\n",
              " 0.714286,\n",
              " 0.75,\n",
              " 0.8,\n",
              " 0.833329,\n",
              " 0.875,\n",
              " 0.888886,\n",
              " 1.0,\n",
              " 1.14286,\n",
              " 1.16667,\n",
              " 1.2,\n",
              " 1.25,\n",
              " 1.33333,\n",
              " 1.4,\n",
              " 1.5,\n",
              " 1.6,\n",
              " 1.66667,\n",
              " 1.75,\n",
              " 1.77143,\n",
              " 1.8,\n",
              " 1.83333,\n",
              " 1.95239,\n",
              " 1.97143,\n",
              " 2.0,\n",
              " 2.0463,\n",
              " 2.05556,\n",
              " 2.07407,\n",
              " 2.0963,\n",
              " 2.11729,\n",
              " 2.12037,\n",
              " 2.12346,\n",
              " 2.16049,\n",
              " 2.16667,\n",
              " 2.18519,\n",
              " 2.2,\n",
              " 2.24074,\n",
              " 2.24691,\n",
              " 2.25,\n",
              " 2.33333,\n",
              " 2.34815,\n",
              " 2.37037,\n",
              " 2.375,\n",
              " 2.4,\n",
              " 2.40741,\n",
              " 2.42857,\n",
              " 2.5,\n",
              " 2.58025,\n",
              " 2.61111,\n",
              " 2.66667,\n",
              " 2.74074,\n",
              " 2.75,\n",
              " 2.85714,\n",
              " 2.87037,\n",
              " 2.91358,\n",
              " 3.0,\n",
              " 3.1625,\n",
              " 3.21666,\n",
              " 3.25,\n",
              " 3.33333,\n",
              " 3.4,\n",
              " 3.5,\n",
              " 3.53,\n",
              " 3.58125,\n",
              " 3.66667,\n",
              " 3.75,\n",
              " 3.8,\n",
              " 4.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCyt9tRTyA1y",
        "colab_type": "text"
      },
      "source": [
        "Во-первых, у нас 72 класса — это очень много для классификации. Во-вторых, сейчас данные больше похожи на что-то непрерывное — повод использовать регрессию, а не классификацию."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EttSzVG2x-87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t7wQmhheYl0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "clf = LinearSVC()\n",
        "clf.fit(X_train, y_train) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzV-2mIfeYmB",
        "colab_type": "text"
      },
      "source": [
        "#### Ранжируем с RandomForestRegressor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGNiFR-9eYmD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "b0e05c54-9735-403a-8f62-0f00f5748e1f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor()\n",
        "gs_rf = GridSearchCV(rf, {'max_depth':[8, None]}, cv=5)\n",
        "gs_rf.fit(X_train, y=y_train)\n",
        "\n",
        "\n",
        "labels_predicted_rf = gs_rf.best_estimator_.predict(X_test)\n"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-mElKbSrNL0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "298021f5-8aa4-4e05-ae83-33e0cae9826f"
      },
      "source": [
        "gs_rf.best_estimator_"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=8,\n",
              "                      max_features='auto', max_leaf_nodes=None,\n",
              "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                      min_samples_leaf=1, min_samples_split=2,\n",
              "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                      n_jobs=None, oob_score=False, random_state=None,\n",
              "                      verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzurTxKBZvW9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a336032d-a6f5-46d4-dfbf-05426c003b1b"
      },
      "source": [
        "score_rf = get_nDCG_score(\n",
        "    queries = queries_id_test, \n",
        "    queries_lines_info = queries_lines_info, \n",
        "    test_queries_lines_info = test_queries_lines_info, \n",
        "    labels_true = y_test, \n",
        "    labels_predicted = labels_predicted_rf\n",
        ")\n",
        " \n",
        "score_rf"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8323207796046446"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCRaopuheYmJ",
        "colab_type": "text"
      },
      "source": [
        "#### Ранжируем с XGBoost"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqIboWMaeYmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "# read in data\n",
        "# dtrain = xgb.DMatrix(X_train)\n",
        "# dtest = xgb.DMatrix(X_test)\n",
        "# specify parameters via map\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dtest = xgb.DMatrix(X_test, label=y_test)\n",
        "depth = range(5, 10)\n",
        "results = []\n",
        "for i in depth:\n",
        "    param = {'max_depth': i}\n",
        "    num_round = 2\n",
        "    bst = xgb.train(param, dtrain, num_round)\n",
        "    preds = bst.predict(dtest)\n",
        "    score_xgb = get_nDCG_score(\n",
        "        queries = queries_id_test, \n",
        "        queries_lines_info = queries_lines_info, \n",
        "        test_queries_lines_info = test_queries_lines_info, \n",
        "        labels_true = y_test, \n",
        "        labels_predicted = preds\n",
        "        )\n",
        "    results.append((i, score_xgb))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KPE5B24f6Ii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "4639c376-bc88-4aab-e8dd-33919798545d"
      },
      "source": [
        "for depth, score in results:\n",
        "    print('При максимальной глубине {0} score {1}'.format(depth, score))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "При максимальной глубине 5 score 0.8186096850795688\n",
            "При максимальной глубине 6 score 0.820581144976179\n",
            "При максимальной глубине 7 score 0.8247841812356328\n",
            "При максимальной глубине 8 score 0.8254303627044434\n",
            "При максимальной глубине 9 score 0.8233549584713931\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PTRNXCDaizOj",
        "colab_type": "text"
      },
      "source": [
        "Как видно, лучший результат на глубине 8."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsTKvy6ik2uM",
        "colab_type": "text"
      },
      "source": [
        "Попробуем другую модель?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l2Rzyba3kSjR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1381a2ae-3274-4806-fb68-10d0a3632aca"
      },
      "source": [
        "param = {'max_depth': 8, 'objective':'rank:pairwise'}\n",
        "num_round = 2\n",
        "bst = xgb.train(param, dtrain, num_round)\n",
        "preds = bst.predict(dtest)\n",
        "score_xgb = get_nDCG_score(\n",
        "    queries = queries_id_test, \n",
        "    queries_lines_info = queries_lines_info, \n",
        "    test_queries_lines_info = test_queries_lines_info, \n",
        "    labels_true = y_test, \n",
        "    labels_predicted = preds\n",
        "    )\n",
        "    \n",
        "score_xgb"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8175462144248398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxgKTcTKk1xA",
        "colab_type": "text"
      },
      "source": [
        "Ну, от добра добра не ищут (хотя можно сделать gridsearch и подобрать хорошие параметры)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynp7zRfveYmQ",
        "colab_type": "text"
      },
      "source": [
        "#### Ранжируем с LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP9Pqxu4eYmX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import lightgbm\n",
        "\n",
        "dtrain = lightgbm.Dataset(X_train, label=y_train)\n",
        "dtest = lightgbm.Dataset(X_test, label=y_test)\n",
        "\n",
        "lgbm = lightgbm.train({'num_leaves':70, 'max_depth':8}, dtrain)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoLM8TZpeYmg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_predicted_lgbm = lgbm.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUjhDVlVnsMo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eddc0ba0-ef32-4212-c4bd-36835744c014"
      },
      "source": [
        "score_lgbm = get_nDCG_score(\n",
        "    queries = queries_id_test, \n",
        "    queries_lines_info = queries_lines_info, \n",
        "    test_queries_lines_info = test_queries_lines_info, \n",
        "    labels_true = y_test, \n",
        "    labels_predicted = labels_predicted_lgbm\n",
        "    )\n",
        "    \n",
        "score_lgbm"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8521957028509198"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CG4sx5yQynC5",
        "colab_type": "text"
      },
      "source": [
        "LightGBM победил, расходимся."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CeQN-x6we7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}